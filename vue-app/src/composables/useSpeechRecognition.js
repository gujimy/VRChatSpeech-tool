import { ref, onUnmounted } from 'vue'

/**
 * è¯­éŸ³è¯†åˆ«ç»„åˆå¼å‡½æ•°
 * å°è£… Web Speech API çš„è¯­éŸ³è¯†åˆ«åŠŸèƒ½
 */
export function useSpeechRecognition() {
  const status = ref('åˆå§‹åŒ–ä¸­...')
  const isRecognizing = ref(false)
  const interimText = ref('')
  const lang = ref('zh-CN')
  
  let recognition = null
  // let stream = null // ç”± useMicrophone ç»Ÿä¸€ç®¡ç†
  let maxSensitivity = 0
  let sensitivityThreshold = 0
  let visibilityCheckInterval = null

  /**
   * åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
   */
  const init = async () => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
    
    if (!SpeechRecognition) {
      status.value = 'ä¸æ”¯æŒ'
      console.error('æµè§ˆå™¨ä¸æ”¯æŒ Web Speech API')
      return false
    }
    
    recognition = new SpeechRecognition()
    recognition.continuous = true
    recognition.interimResults = true
    recognition.lang = lang.value
    recognition.maxAlternatives = 1
    
    status.value = 'å°±ç»ª'
    return true
  }

  /**
   * åˆå§‹åŒ–éŸ³é¢‘çµæ•åº¦æ£€æµ‹
   * @param {MediaStream} stream - å¤–éƒ¨ä¼ å…¥çš„éŸ³é¢‘æµ
   */
  const initSensitivity = async (stream) => {
    if (!stream) {
      console.error('åˆå§‹åŒ–çµæ•åº¦æ£€æµ‹å¤±è´¥: æœªæä¾› MediaStream')
      return false
    }
    
    try {
      const audioContext = new AudioContext()
      const mediaStreamAudioSourceNode = audioContext.createMediaStreamSource(stream)
      const analyserNode = audioContext.createAnalyser()
      mediaStreamAudioSourceNode.connect(analyserNode)

      const pcmData = new Float32Array(analyserNode.fftSize)
      const onFrame = () => {
        // æµçš„ç”Ÿå‘½å‘¨æœŸç”±å¤–éƒ¨ç®¡ç†ï¼Œè¿™é‡Œä¸å†æ£€æŸ¥
        analyserNode.getFloatTimeDomainData(pcmData)
        let sumSquares = 0.0
        for (const amplitude of pcmData) {
          sumSquares += amplitude * amplitude
        }
        const currentSensitivity = Math.sqrt(sumSquares / pcmData.length)
        
        if (currentSensitivity > maxSensitivity) {
          maxSensitivity = currentSensitivity
        }
        
        window.requestAnimationFrame(onFrame)
      }
      window.requestAnimationFrame(onFrame)
      
      console.log('ðŸŽ¤ éº¦å…‹é£Žæƒé™å·²èŽ·å–')
      return true
    } catch (e) {
      console.error('éº¦å…‹é£Žæƒé™è¢«æ‹’ç»æˆ–ä¸å¯ç”¨:', e)
      return false
    }
  }

  /**
   * è®¾ç½®è¯†åˆ«äº‹ä»¶å¤„ç†å™¨
   */
  const setupEvents = (onResult, onError) => {
    if (!recognition) return

    recognition.onstart = () => {
      isRecognizing.value = true
      status.value = 'æ­£åœ¨è¯†åˆ«...'
    }
    
    recognition.onresult = (event) => {
      // æ£€æŸ¥çµæ•åº¦é—¨é™ï¼ˆå°† 0-100 çš„ç”¨æˆ·è®¾ç½®è½¬æ¢ä¸º 0-1 çš„é˜ˆå€¼ï¼‰
      const threshold = sensitivityThreshold / 100
      if (sensitivityThreshold > 0 && maxSensitivity < threshold) {
        console.log(`ðŸ”‡ éŸ³é‡è¿‡ä½Ž: ${(maxSensitivity * 100).toFixed(1)} < ${sensitivityThreshold}, å·²å¿½ç•¥`)
        return
      }
      
      let interim = ''
      let final = ''
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript
        if (event.results[i].isFinal) {
          final += transcript
        } else {
          interim += transcript
        }
      }
      
      interimText.value = interim
      
      if (final) {
        maxSensitivity = 0
        interimText.value = ''
        if (onResult) {
          onResult(final.trim())
        }
      }
    }
    
    recognition.onerror = (event) => {
      // é”™è¯¯ç±»åž‹æ˜ å°„å’Œç”¨æˆ·å‹å¥½æç¤º
      const errorMessages = {
        'no-speech': { log: false, message: 'æœªæ£€æµ‹åˆ°è¯­éŸ³' },
        'aborted': { log: false, message: 'è¯†åˆ«å·²ä¸­æ­¢' },
        'audio-capture': { log: true, message: 'æ— æ³•è®¿é—®éº¦å…‹é£Žï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®' },
        'network': { log: true, message: 'ç½‘ç»œè¿žæŽ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ' },
        'not-allowed': { log: true, message: 'éº¦å…‹é£Žæƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸' },
        'service-not-allowed': { log: true, message: 'è¯­éŸ³è¯†åˆ«æœåŠ¡ä¸å¯ç”¨' },
        'bad-grammar': { log: true, message: 'è¯­æ³•é”™è¯¯' },
        'language-not-supported': { log: true, message: 'ä¸æ”¯æŒå½“å‰è¯­è¨€' }
      }
      
      const errorInfo = errorMessages[event.error] || { log: true, message: `æœªçŸ¥é”™è¯¯: ${event.error}` }
      
      // æ ¹æ®é”™è¯¯ç±»åž‹å†³å®šæ˜¯å¦è®°å½•æ—¥å¿—
      if (errorInfo.log) {
        console.error(`âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯ [${event.error}]:`, errorInfo.message)
        status.value = errorInfo.message
        
        if (onError) {
          onError(errorInfo.message)
        }
      } else {
        // é™é»˜é”™è¯¯ï¼Œä»…è®°å½•è°ƒè¯•ä¿¡æ¯
        console.debug(`ðŸ”‡ è¯­éŸ³è¯†åˆ«: ${errorInfo.message}`)
      }
    }
    
    recognition.onend = () => {
      if (isRecognizing.value) {
        // è‡ªåŠ¨é‡å¯è¯†åˆ«
        setTimeout(() => {
          if (isRecognizing.value && recognition) {
            try {
              recognition.start()
            } catch (e) {
              console.error(`é‡å¯å¤±è´¥: ${e.message}`)
            }
          }
        }, 100)
      } else {
        status.value = 'å·²åœæ­¢'
      }
    }
  }

  /**
   * å¼€å§‹è¯†åˆ«
   */
  const start = () => {
    if (!recognition || isRecognizing.value) return
    
    try {
      recognition.start()
      console.log('ðŸŽ™ï¸ è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨')
      
      // å¯åŠ¨åŽå°æ£€æµ‹
      startVisibilityCheck()
    } catch (e) {
      status.value = 'å¯åŠ¨å¤±è´¥'
      console.error('âŒ å¯åŠ¨è¯†åˆ«å¤±è´¥:', e)
    }
  }
  
  /**
   * å¯åŠ¨é¡µé¢å¯è§æ€§æ£€æµ‹
   * å½“é¡µé¢ä»ŽåŽå°åˆ‡æ¢å›žå‰å°æ—¶,æ£€æŸ¥å¹¶æ¢å¤è¯†åˆ«
   */
  const startVisibilityCheck = () => {
    if (visibilityCheckInterval) return
    
    document.addEventListener('visibilitychange', handleVisibilityChange)
    
    // å®šæœŸæ£€æŸ¥è¯†åˆ«çŠ¶æ€
    visibilityCheckInterval = setInterval(() => {
      if (isRecognizing.value && recognition && document.visibilityState === 'visible') {
        // å¦‚æžœåº”è¯¥åœ¨è¯†åˆ«ä½†å¯èƒ½è¢«æš‚åœ,å°è¯•é‡å¯
        try {
          // æ£€æŸ¥æ˜¯å¦çœŸçš„åœ¨è¿è¡Œ,å¦‚æžœæ²¡æœ‰å°±é‡å¯
          if (status.value === 'å°±ç»ª' || status.value === 'å·²åœæ­¢') {
            console.log('ðŸ”„ æ£€æµ‹åˆ°è¯†åˆ«å¯èƒ½å·²åœæ­¢,å°è¯•æ¢å¤...')
            recognition.start()
          }
        } catch (e) {
          // å¦‚æžœå·²ç»åœ¨è¿è¡Œä¼šæŠ›å‡ºé”™è¯¯,è¿™æ˜¯æ­£å¸¸çš„
          if (!e.message.includes('already started')) {
            console.error('æ¢å¤è¯†åˆ«å¤±è´¥:', e)
          }
        }
      }
    }, 3000) // æ¯3ç§’æ£€æŸ¥ä¸€æ¬¡
  }
  
  /**
   * å¤„ç†é¡µé¢å¯è§æ€§å˜åŒ–
   */
  const handleVisibilityChange = () => {
    if (document.visibilityState === 'visible' && isRecognizing.value && recognition) {
      console.log('ðŸ“± é¡µé¢åˆ‡æ¢åˆ°å‰å°,æ£€æŸ¥è¯†åˆ«çŠ¶æ€...')
      setTimeout(() => {
        try {
          if (status.value !== 'æ­£åœ¨è¯†åˆ«...') {
            console.log('ðŸ”„ æ¢å¤è¯­éŸ³è¯†åˆ«...')
            recognition.start()
          }
        } catch (e) {
          if (!e.message.includes('already started')) {
            console.error('æ¢å¤è¯†åˆ«å¤±è´¥:', e)
          }
        }
      }, 500)
    }
  }
  
  /**
   * åœæ­¢é¡µé¢å¯è§æ€§æ£€æµ‹
   */
  const stopVisibilityCheck = () => {
    if (visibilityCheckInterval) {
      clearInterval(visibilityCheckInterval)
      visibilityCheckInterval = null
    }
    document.removeEventListener('visibilitychange', handleVisibilityChange)
  }

  /**
   * åœæ­¢è¯†åˆ«
   */
  const stop = () => {
    if (!recognition || !isRecognizing.value) return
    
    isRecognizing.value = false
    recognition.stop()
    interimText.value = ''
    
    // åœæ­¢åŽå°æ£€æµ‹
    stopVisibilityCheck()
  }

  /**
   * æ›´æ”¹è¯†åˆ«è¯­è¨€
   * éœ€è¦é‡å¯è¯†åˆ«æ‰èƒ½åº”ç”¨æ–°è¯­è¨€
   */
  const changeLang = (newLang) => {
    const wasRecognizing = isRecognizing.value
    lang.value = newLang
    
    if (recognition) {
      // å…ˆåœæ­¢å½“å‰è¯†åˆ«
      if (wasRecognizing) {
        isRecognizing.value = false
        try {
          recognition.abort() // ä½¿ç”¨ abort ç«‹å³åœæ­¢ï¼Œè€Œä¸æ˜¯ stop
        } catch (e) {
          // å¿½ç•¥åœæ­¢æ—¶çš„é”™è¯¯
        }
      }
      
      // æ›´æ–°è¯­è¨€è®¾ç½®
      recognition.lang = newLang
      console.log(`ðŸŒ è¯­è¨€å·²åˆ‡æ¢åˆ°: ${newLang}`)
      
      // å¦‚æžœä¹‹å‰åœ¨è¯†åˆ«ï¼Œåˆ™é‡æ–°å¯åŠ¨
      if (wasRecognizing) {
        setTimeout(() => {
          isRecognizing.value = true
          try {
            recognition.start()
            console.log('ðŸŽ™ï¸ è¯­éŸ³è¯†åˆ«å·²é‡å¯ï¼ˆæ–°è¯­è¨€ï¼‰')
          } catch (e) {
            console.error('é‡å¯è¯†åˆ«å¤±è´¥:', e)
            isRecognizing.value = false
          }
        }, 200) // ç»™ä¸€ç‚¹å»¶è¿Ÿç¡®ä¿ä¹‹å‰çš„è¯†åˆ«å®Œå…¨åœæ­¢
      }
    }
  }

  /**
   * è®¾ç½®çµæ•åº¦é—¨é™
   */
  const setSensitivity = (value) => {
    sensitivityThreshold = value
  }

  /**
   * æ¸…ç†èµ„æº
   */
  const cleanup = () => {
    stopVisibilityCheck()
    
    if (recognition) {
      recognition.stop()
      recognition = null
    }
    // æµçš„æ¸…ç†äº¤ç”± useMicrophone å¤„ç†
    // if (stream) {
    //   stream.getTracks().forEach(track => track.stop())
    //   stream = null
    // }
  }

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  onUnmounted(() => {
    cleanup()
  })

  return {
    status,
    isRecognizing,
    interimText,
    lang,
    init,
    initSensitivity,
    setupEvents,
    start,
    stop,
    changeLang,
    setSensitivity,
    cleanup
  }
}